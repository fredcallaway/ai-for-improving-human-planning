{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import matplotlib as plt\n",
    "import itertools as it\n",
    "from analysis_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT = 4\n",
    "\n",
    "os.makedirs(f'stats/{EXPERIMENT}', exist_ok=True)\n",
    "def write_tex(name, tex):\n",
    "    file = f\"stats/{EXPERIMENT}/{name}.tex\"\n",
    "    with open(file, \"w+\") as f:\n",
    "        f.write(str(tex) + r\"\\unskip\")\n",
    "    print(f'wrote \"{tex}\" to \"{file}\"')\n",
    "\n",
    "data = get_data(EXPERIMENT)\n",
    "pdf = data['participants'].set_index('pid').copy()\n",
    "full_pdf = pdf.copy()\n",
    "mdf = data['trials'].set_index('pid').copy()\n",
    "mdf.trial_time /= 1000\n",
    "mdf['clicked'] = mdf.n_clicks > 0\n",
    "\n",
    "if EXPERIMENT == 3:\n",
    "    pdf.query('completed_1', inplace=True)\n",
    "else:\n",
    "    pdf.query('completed', inplace=True)\n",
    "    \n",
    "\n",
    "if EXPERIMENT == 4:\n",
    "    fb_namer = {\n",
    "        (0, 0): 'none',\n",
    "        (1, 0): 'info_only',\n",
    "        (0, 1): 'reward_only',\n",
    "        (1, 1): 'both'\n",
    "    }\n",
    "    pdf['feedback'] = pdf.apply(lambda row: fb_namer[row.information, row.reward], axis=1)\n",
    "    mdf['information'] = pdf.information\n",
    "    mdf['reward'] = pdf.reward\n",
    "    fb_order = list(fb_namer.values())\n",
    "else:\n",
    "    fb_order = [fb for fb in ['none', 'action', 'meta'] if fb in set(pdf.feedback)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pids = list(pdf.index.unique())\n",
    "sdf = data['survey'].query('pid == @pids').copy()\n",
    "if not isinstance(sdf.responses.iloc[0], dict):\n",
    "    sdf = sdf.loc[~sdf.responses.isna()]\n",
    "    sdf.responses = sdf.responses.apply(ast.literal_eval)\n",
    "\n",
    "if EXPERIMENT == 3:\n",
    "    demo = sdf.loc[sdf.responses.apply(len) == 3].set_index('pid').responses\n",
    "    age = demo.apply(get('Q1'))\n",
    "    gender = demo.apply(get('Q2'))\n",
    "else:\n",
    "    demo = sdf.loc[sdf.responses.apply(len) == 2].set_index('pid').responses\n",
    "    age = demo.apply(get('Q0'))\n",
    "    gender = demo.apply(get('Q1'))\n",
    "    \n",
    "gender = gender.str.lower()\n",
    "age = age.apply(excepts(ValueError, int, lambda _: None))\n",
    "\n",
    "write_tex('mean-age', f'{age.mean():.2f}')\n",
    "write_tex('min-age', str(age.min()))\n",
    "write_tex('max-age', str(age.max()))\n",
    "\n",
    "regularize = {\n",
    "    'man': 'male',\n",
    "    'woman': 'female',\n",
    "    'f': 'female',\n",
    "    'm': 'male',\n",
    "}\n",
    "gender = gender.apply(lambda x: regularize.get(x.strip(), x))\n",
    "write_tex(\"N-female\", str(gender.value_counts()['female']))\n",
    "\n",
    "write_tex(\"N-total\", f\"${len(pdf)}$\")\n",
    "for fb, n in pdf.feedback.value_counts().items():\n",
    "    write_tex(f\"N-{fb}\", f\"${n}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPERIMENT == 3:\n",
    "    dropped = pdf.query('not completed').feedback.value_counts()\n",
    "    rate = dropped / pdf.feedback.value_counts()\n",
    "    for fb in fb_order:\n",
    "        write_tex(f'N-drop-{fb}', dropped[fb])\n",
    "        write_tex(f'drop-rate-{fb}', f'${rate[fb]*100:.1f}\\%$')\n",
    "    write_tex('return-rate', f'${pdf.completed.mean()*100:.1f}\\%$')\n",
    "    write_tex('return-N', f'${pdf.completed.sum()}$')\n",
    "    pdf.query('completed', inplace=True)\n",
    "    \n",
    "pd.Series(pdf.index).to_csv(f'pids/{EXPERIMENT}.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed = list(pdf.index)\n",
    "mdf.reset_index(inplace=True)\n",
    "mdf.query('pid == @completed', inplace=True)\n",
    "mdf.set_index('pid', inplace=True)\n",
    "\n",
    "pdf.feedback = pd.Categorical(pdf.feedback, fb_order, ordered=True)    \n",
    "mdf['feedback'] = pdf.feedback\n",
    "block_mean = mdf.groupby(['block', 'pid']).score.mean()\n",
    "for b in ['training', 'test']:\n",
    "    pdf[b] = block_mean[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf['pay'] = (0.50 + pdf.bonus)\n",
    "# pdf['wage'] = pdf.pay / (pdf.total_time / 60)\n",
    "\n",
    "# sns.distplot(pdf.wage)\n",
    "# plt.axvline(pdf.wage.mean(), c='r', ls='--')\n",
    "\n",
    "# print(f'The average duration of the experiment was {pdf.total_time.mean():.2f} min +/- {pdf.total_time.std():.2f} min.')\n",
    "# print(f'The average bonus was ${pdf.bonus.mean():.2f} +/- ${pdf.bonus.std():.2f}.')\n",
    "# print(f'The average wage was ${pdf.wage.mean():.2f}/hr +/- ${pdf.wage.std():.2f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = Figures(path=f'figs/{EXPERIMENT}', formats=['pdf', 'png']).plot\n",
    "\n",
    "sns.set_style('white')\n",
    "blue, orange = sns.color_palette('tab10')[:2]\n",
    "gray = (0.5,)*3\n",
    "red = (1, 0.3, 0.4)\n",
    "yellow = (1, 0.9, 0.4)\n",
    "palette = {\n",
    "    'none': gray,\n",
    "    'action': blue,\n",
    "    'meta': orange,\n",
    "    'info_only': red,\n",
    "    'reward_only': yellow,\n",
    "    'both': orange,\n",
    "}\n",
    "\n",
    "palette = {\n",
    "    'none': gray,\n",
    "    'action': blue,\n",
    "    'meta': orange,\n",
    "    'info_only': red,\n",
    "    'reward_only': yellow,\n",
    "    'both': orange,\n",
    "}\n",
    "\n",
    "nice_names = {\n",
    "    'meta': 'Metacognitive',\n",
    "    'action': 'Action',\n",
    "    'none': 'None',\n",
    "    'feedback': 'Feedback',\n",
    "    'info_only': 'Information\\nOnly',\n",
    "    'reward_only': 'Reward\\nOnly',\n",
    "    'both': 'Information &\\nReinforcement',\n",
    "    'score': 'Average Score',\n",
    "}\n",
    "\n",
    "def reformat_labels(ax=None):\n",
    "    ax = ax or plt.gca()\n",
    "    labels = [t.get_text() for t in ax.get_xticklabels()]\n",
    "    new_labels = [nice_names.get(lab, lab) for lab in labels]\n",
    "    ax.set_xticklabels(new_labels)\n",
    "    \n",
    "def reformat_legend(ax=None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    print([nice_names.get(l, l).replace('\\n', ' ') for l in labels])\n",
    "    ax.legend(handles=handles, labels=[nice_names.get(l, l).replace('\\n', ' ') \n",
    "                                       for l in labels])\n",
    "    \n",
    "def plot_block_changes():\n",
    "    block_changes = mdf.loc[1].block.apply(Labeler()).diff().reset_index().query('block == 1').index\n",
    "    for t in block_changes:\n",
    "        plt.axvline(t-0.5, c='k', ls='--')\n",
    "\n",
    "from datetime import datetime\n",
    "# os.makedirs(f'stats/{EXPERIMENT}/', exist_ok=True)\n",
    "def result_file(name, ext='tex'):\n",
    "    file = f'stats/{EXPERIMENT}-{name}.{ext}'\n",
    "#     with open(file, 'w+') as f:\n",
    "#         timestamp = datetime.now().strftime('Created on %m/%d/%y at %H:%M:%S\\n\\n')\n",
    "#         f.write(timestamp)\n",
    "    return file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@figure()\n",
    "def plot_test():\n",
    "    if EXPERIMENT == 4:\n",
    "        plt.figure(figsize=(12,4))\n",
    "    sns.set_style('whitegrid')\n",
    "    sns.swarmplot('feedback', 'test', data=pdf, palette=palette, alpha=0.5, order=fb_order)\n",
    "    sns.pointplot('feedback', 'test', data=pdf, palette=palette, order=fb_order, \n",
    "                  scale=1, capsize=0.1, markers='o')\n",
    "    plt.xlabel('Feedback')\n",
    "    plt.ylabel(nice_names['score'])\n",
    "    test = 'Test' if EXPERIMENT == 1 else 'Transfer'\n",
    "    reformat_labels()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kruskal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = pdf[['test', 'feedback']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i rdf -o out\n",
    "out = kruskal.test(test ~ feedback, data=rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = dict(out.items())\n",
    "df = out[\"parameter\"][0]\n",
    "p = pval(out[\"p.value\"][0])\n",
    "stat = out[\"statistic\"][0]\n",
    "write_tex('score-kruskal', rf'$\\chi^2({df}) = {stat:.3f}, {p}$')\n",
    "# p = pvalue(out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_BOOT = 10000\n",
    "test_score = pdf.set_index('feedback').test\n",
    "\n",
    "def ci(xs):\n",
    "    return np.quantile(xs, [0.025, 0.975])\n",
    "\n",
    "def boot_means(n=N_BOOT):\n",
    "    r = {}\n",
    "    for fb in fb_order:\n",
    "        x = test_score.loc[fb]\n",
    "        means = [x.sample(frac=1, replace=True).mean() for _ in range(n)]\n",
    "        r[fb] = np.array(means)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm = boot_means()\n",
    "for fb in fb_order:\n",
    "    x = test_score.loc[fb].mean()\n",
    "    a, b = ci(bm[fb])\n",
    "    if fb == 'none':\n",
    "        tex = (rf'${x:.2f}$ points/trial (95\\% CI: [${a:.2f}$, ${b:.2f}$])')\n",
    "    else:\n",
    "        tex = (rf'${x:.2f}$ points/trial; 95\\% CI: [${a:.2f}$, ${b:.2f}$]')\n",
    "    write_tex(f'mean-{fb}', tex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differences by permutation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_mean_diff_samples(c1, c2, n=N_BOOT):\n",
    "    r = []\n",
    "    x = test_score.copy()\n",
    "    for i in range(n):\n",
    "        np.random.shuffle(x.values)\n",
    "        r.append(x.loc[c1].mean() - x.loc[c2].mean())\n",
    "    return np.array(r)\n",
    "\n",
    "#         x = test_score.sample(n=n_fb[c1], replace=True)\n",
    "#         y = test_score.sample(n=n_fb[c2], replace=True)\n",
    "#         r.append(x.mean() - y.mean())\n",
    "\n",
    "def report(c1, c2, n=N_BOOT):\n",
    "    actual_diff = test_score.loc[c1].mean() - test_score.loc[c2].mean()\n",
    "    null_diff = null_mean_diff_samples(c1, c2, n=n)\n",
    "#     p = (1 + np.sum(abs(null_diff) >= abs(actual_diff))) / (n+1)\n",
    "    p = np.mean(abs(null_diff) >= abs(actual_diff))\n",
    "    write_tex(f'permutation-{c1}-{c2}', f'${pval(p)}$')\n",
    "\n",
    "if EXPERIMENT == 4:\n",
    "    report('both', 'none')\n",
    "    report('info_only', 'none')\n",
    "    report('reward_only', 'none')\n",
    "    report('both', 'reward_only')\n",
    "    report('both', 'info_only')\n",
    "else:\n",
    "    report('meta', 'none')\n",
    "    if 'action' in fb_order:\n",
    "        report('meta', 'action')\n",
    "        report('action', 'none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary in test block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_block = mdf.query('block == \"test\"').copy()\n",
    "first_click = test_block.clicks.apply(get(0, default=None))\n",
    "test_block['no_click'] = first_click.isna()\n",
    "test_block['clicked'] = ~test_block.no_click\n",
    "\n",
    "if EXPERIMENT == 1:\n",
    "    leaves = {3,4,7,8,11,12}\n",
    "else:  # transfer\n",
    "    leaves = {5, 6, 7, 9, 10, 11, 16, 17, 18, 20, 21, 22, 27, 28, 29, 31, 32, 33}\n",
    "    \n",
    "x = first_click.isin(leaves)\n",
    "x[test_block.no_click] = np.nan\n",
    "test_block['backward'] = x\n",
    "\n",
    "test_block.backward.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare\n",
    "rate = test_block.groupby('feedback').n_clicks.mean()\n",
    "\n",
    "def report_ratio(df, key):\n",
    "    name = key.replace('_', '-')\n",
    "    X = df.groupby(['feedback', key]).apply(len)\n",
    "    rate = 100 * df.groupby('feedback')[key].mean()\n",
    "\n",
    "    for c in fb_order:\n",
    "        r = rate[c]\n",
    "        write_tex(f'{name}-{c}-percent', f\"${r:.1f}$\\%\")\n",
    "\n",
    "#     for c in 'action', 'none':\n",
    "#         if c not in fb_order:\n",
    "#             continue\n",
    "#         stat, p = chisquare(X['meta'], X[c])\n",
    "#         tex = rf'$\\chi^2(1) = {int(stat)}, {pval(p)}$'\n",
    "#         write_tex(f'{name}-meta-{c}', tex)\n",
    "\n",
    "# for c in fb_order:\n",
    "#     r = rate[c]\n",
    "#     write_tex(f'clicks-{c}', f\"${r:.2f}$\")\n",
    "# report_ratio(test_block, 'no_click')\n",
    "report_ratio(test_block, 'backward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_leaves = {3,4,7,8,11,12}\n",
    "transfer_leaves = {5, 6, 7, 9, 10, 11, 16, 17, 18, 20, 21, 22, 27, 28, 29, 31, 32, 33}\n",
    "\n",
    "def clicked_leaf_first(row):\n",
    "    if not row.clicks:\n",
    "        return False\n",
    "    first = row.clicks[0]\n",
    "    transfer =  EXPERIMENT in (2, 3) and row.block == \"test\"\n",
    "    leaves = transfer_leaves if transfer else small_leaves\n",
    "    return first in leaves\n",
    "\n",
    "mdf['backward'] = mdf.apply(clicked_leaf_first, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolz.curried import get\n",
    "sns.set_style('whitegrid')\n",
    "@figure()\n",
    "def plot_backward_training():\n",
    "#     df = mdf.query('block == \"training\"').copy()\n",
    "    df = mdf.copy()\n",
    "    df.trial_index += 1\n",
    "    sns.lineplot('trial_index', 'backward', hue='feedback', \n",
    "                 data=df, hue_order=fb_order, palette=palette)\n",
    "    plt.ylabel('Proportion Planning Backward')\n",
    "    plt.xlabel('Trial Number')\n",
    "    plt.gca().grid(axis='x')\n",
    "    split = mdf.query('block == \"training\"').trial_index.max()\n",
    "    plt.axvline(split+1.5, c='k', ls='--', alpha=0.3)\n",
    "#     plt.ylim(0, 1)\n",
    "    plt.xlim(df.trial_index.min(), df.trial_index.max())\n",
    "    reformat_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mediation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = test_block.copy().rename(columns={'information': 'info'})\n",
    "# rdf['feedback'] = (rdf.feedback != 'none').astype(int)\n",
    "\n",
    "if EXPERIMENT == 4:\n",
    "    factors = ['info', 'reward']\n",
    "    for c in factors:\n",
    "        rdf[c] = rdf[c].astype(float)\n",
    "else:\n",
    "    factors = ['action', 'meta']\n",
    "    fb = rdf.pop('feedback')\n",
    "    for c in factors:\n",
    "        rdf[c] = (fb == c).astype(int)\n",
    "\n",
    "rdf['clicked'] = rdf.clicked.astype(int)\n",
    "rdf = rdf[[*factors, 'backward', 'clicked', 'n_clicks', 'score', 'trial_index', 'stim_i']].reset_index()\n",
    "rdf.backward.fillna(0, inplace=True)\n",
    "# rdf.trial_index = rdf.trial_index.astype(float)\n",
    "# rdf.query('action == 0', inplace=True)\n",
    "rdf = rdf.groupby('pid').mean()\n",
    "rdf.trial_index -= rdf.trial_index.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i rdf -o score\n",
    "fit = lm(score ~ backward, data=rdf)\n",
    "score = summary(fit)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = dict(score.items())\n",
    "df = score['df'][1]\n",
    "est, std, t, p = score['coefficients'][1]\n",
    "write_tex(f'score-backward', f'${est:.3f}$')\n",
    "write_tex(f'score-backward-test', f'$t({df}) = {t:.3f}$, ${pval(p)}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i rdf -i EXPERIMENT -o back -o med_out\n",
    "library(mediation)\n",
    "\n",
    "if (EXPERIMENT == 1) {\n",
    "    back_fit = lm(backward ~ action + meta, data=rdf)\n",
    "    score_fit = lm(score ~ backward + action + meta, data=rdf)\n",
    "} else {\n",
    "    back_fit = lm(backward ~ meta, data=rdf)\n",
    "    score_fit = lm(score ~ backward + meta, data=rdf)\n",
    "}\n",
    "med_out = mediate(back_fit, score_fit, treat=\"meta\", mediator=\"backward\")\n",
    "back = summary(back_fit)\n",
    "summary(med_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "back = dict(back.items())\n",
    "df = back['df'][1]\n",
    "for i, name in enumerate(fb_order[1:], start=1):\n",
    "    est, std, t, p = back['coefficients'][i]\n",
    "    write_tex(f'backward-lm-{name}', f'$t({df}) = {t:.3f}$, ${pval(p)}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {\n",
    "    'acme': 'd0',\n",
    "    'ade': 'z0',\n",
    "    'total': 'tau',\n",
    "    'prop': 'n0',\n",
    "}\n",
    "med = dict(med_out.items())\n",
    "\n",
    "for k, v in names.items():\n",
    "    est = med[v + ('.coef' if v == 'tau' else '')][0]\n",
    "    lo, hi = med[v+'.ci']\n",
    "    p = med[v+'.p'][0]\n",
    "    write_tex(f'mediation-{k}', f'{est:.3f}')\n",
    "    write_tex(f'mediation-{k}-ci', f'95\\% CI: [{lo:.3f}, {hi:.3f}], ${pval(p)}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Success!\")"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
