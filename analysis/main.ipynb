{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import matplotlib as plt\n",
    "import itertools as it\n",
    "from analysis_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'feedback'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-55c9b882a48b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mmdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feedback'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'meta'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mfb_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfb\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'action'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'meta'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-55c9b882a48b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mmdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feedback'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'meta'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mfb_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfb\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'action'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'meta'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/miniconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5178\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'feedback'"
     ]
    }
   ],
   "source": [
    "EXPERIMENT = 8\n",
    "\n",
    "if EXPERIMENT == (5, 7, 8):\n",
    "    print(f'Use exp{EXPERIMENT}.ipynb')\n",
    "    exit()\n",
    "\n",
    "os.makedirs(f'stats/{EXPERIMENT}', exist_ok=True)\n",
    "def write_tex(name, tex):\n",
    "    file = f\"stats/{EXPERIMENT}/{name}.tex\"\n",
    "    with open(file, \"w+\") as f:\n",
    "        f.write(str(tex) + r\"\\unskip\")\n",
    "    print(f'wrote \"{tex}\" to \"{file}\"')\n",
    "\n",
    "data = get_data(EXPERIMENT)\n",
    "pdf = data['participants'].rename(columns={'wid': 'pid'}).set_index('pid').copy()\n",
    "full_pdf = pdf.copy()\n",
    "mdf = data['trials'].rename(columns={'wid': 'pid'}).set_index('pid').copy()\n",
    "mdf.trial_time /= 1000\n",
    "mdf['clicked'] = mdf.n_clicks > 0\n",
    "\n",
    "full_pdf = pdf.copy()\n",
    "\n",
    "if EXPERIMENT == 3:\n",
    "    pdf.query('completed_1', inplace=True)\n",
    "else:\n",
    "    pdf.query('completed', inplace=True)\n",
    "    \n",
    "\n",
    "if EXPERIMENT == 6:\n",
    "    pdf.rename(columns={'with_info': 'information', 'with_reward': 'reward'}, inplace=True)\n",
    "    fb_namer = {\n",
    "        (0, 0): 'none',\n",
    "        (1, 0): 'info_only',\n",
    "        (0, 1): 'reward_only',\n",
    "        (1, 1): 'both'\n",
    "    }\n",
    "    pdf['feedback'] = pdf.apply(lambda row: fb_namer[row.information, row.reward], axis=1)\n",
    "    mdf['information'] = pdf.information\n",
    "    mdf['reward'] = pdf.reward\n",
    "    fb_order = list(fb_namer.values())\n",
    "elif EXPERIMENT == 7:\n",
    "    pdf.rename(columns={'constantTest': 'constant_test'}, inplace=True)\n",
    "    mdf['constant_test'] = pdf.constant_test\n",
    "    pdf['feedback'] = 'meta'\n",
    "    mdf['feedback'] = 'meta'\n",
    "else:\n",
    "    fb_order = [fb for fb in ['none', 'action', 'meta'] if fb in set(pdf.feedback)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_score(row):\n",
    "    path = map(int, row.path[1:])\n",
    "    # assert sum(row.state_rewards[p] for p in path) - 3 * len(row.clicks) == row.score\n",
    "    clicks = set(row.clicks)\n",
    "    cost = {'test': 3, 'training': 1}[row.block]\n",
    "    return sum(row.state_rewards[p] if p in clicks else 0 for p in path) - cost * len(clicks)\n",
    "\n",
    "# mdf['expected_score'] = mdf.apply(expected_score, axis=1)\n",
    "# pdf['expected_test'] = mdf.query('block == \"test\"').groupby('pid').expected_score.mean()\n",
    "    \n",
    "# row.state_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote \"34.78\" to \"stats/7/mean-age.tex\"\n",
      "wrote \"18.0\" to \"stats/7/min-age.tex\"\n",
      "wrote \"71.0\" to \"stats/7/max-age.tex\"\n",
      "wrote \"43\" to \"stats/7/N-female.tex\"\n",
      "wrote \"$102$\" to \"stats/7/N-total.tex\"\n",
      "wrote \"$102$\" to \"stats/7/N-meta.tex\"\n",
      "wrote \"\\$1.43\" to \"stats/7/mean-bonus.tex\"\n"
     ]
    }
   ],
   "source": [
    "pids = list(pdf.index.unique())\n",
    "sdf = data['survey'].rename(columns={'wid': 'pid'}).query('pid == @pids').copy()\n",
    "if not isinstance(sdf.responses.iloc[0], dict):\n",
    "    sdf = sdf.loc[~sdf.responses.isna()]\n",
    "    sdf.responses = sdf.responses.apply(ast.literal_eval)\n",
    "\n",
    "if EXPERIMENT == 3:\n",
    "    demo = sdf.loc[sdf.responses.apply(len) == 3].set_index('pid').responses\n",
    "    age = demo.apply(get('Q1'))\n",
    "    gender = demo.apply(get('Q2'))\n",
    "else:\n",
    "    demo = sdf.loc[sdf.responses.apply(len) == 2].set_index('pid').responses\n",
    "    age = demo.apply(get('Q0'))\n",
    "    gender = demo.apply(get('Q1'))\n",
    "    \n",
    "gender = gender.str.lower()\n",
    "age = age.apply(excepts(ValueError, int, lambda _: None))\n",
    "age.loc[age < 18] = None\n",
    "\n",
    "write_tex('mean-age', f'{age.mean():.2f}')\n",
    "write_tex('min-age', str(age.min()))\n",
    "write_tex('max-age', str(age.max()))\n",
    "\n",
    "regularize = {\n",
    "    'man': 'male',\n",
    "    'woman': 'female',\n",
    "    'f': 'female',\n",
    "    'm': 'male',\n",
    "}\n",
    "gender = gender.apply(lambda x: regularize.get(x.strip(), x))\n",
    "write_tex(\"N-female\", str(gender.value_counts()['female']))\n",
    "\n",
    "write_tex(\"N-total\", f\"${len(pdf)}$\")\n",
    "for fb, n in pdf.feedback.value_counts().items():\n",
    "    write_tex(f\"N-{fb}\", f\"${n}$\")\n",
    "    \n",
    "write_tex('mean-bonus', f'\\${pdf.bonus.mean():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed = list(pdf.index)\n",
    "mdf.reset_index(inplace=True)\n",
    "mdf.query('pid == @completed', inplace=True)\n",
    "mdf.set_index('pid', inplace=True)\n",
    "\n",
    "pdf.feedback = pd.Categorical(pdf.feedback, fb_order, ordered=True)    \n",
    "mdf['feedback'] = pdf.feedback\n",
    "block_mean = mdf.groupby(['block', 'pid']).score.mean()\n",
    "for b in ['training', 'test']:\n",
    "    pdf[b] = block_mean[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPERIMENT == 3:\n",
    "    dropped = pdf.query('not completed').feedback.value_counts()\n",
    "    rate = dropped / pdf.feedback.value_counts()\n",
    "    for fb in fb_order:\n",
    "        write_tex(f'N-drop-{fb}', dropped[fb])\n",
    "        write_tex(f'drop-rate-{fb}', f'${rate[fb]*100:.1f}\\%$')\n",
    "    write_tex('return-rate', f'${pdf.completed.mean()*100:.1f}\\%$')\n",
    "    write_tex('return-N', f'${pdf.completed.sum()}$')\n",
    "    pdf.query('completed', inplace=True)\n",
    "    \n",
    "pd.Series(pdf.index).to_csv(f'pids/{EXPERIMENT}.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_leaves = {3,4,7,8,11,12}\n",
    "transfer_leaves = {5, 6, 7, 9, 10, 11, 16, 17, 18, 20, 21, 22, 27, 28, 29, 31, 32, 33}\n",
    "\n",
    "def clicked_leaf_first(row):\n",
    "    if not row.clicks:\n",
    "        return False\n",
    "    first = row.clicks[0]\n",
    "    transfer =  EXPERIMENT in (2, 3) and row.block == \"test\"\n",
    "    leaves = transfer_leaves if transfer else small_leaves\n",
    "    return first in leaves\n",
    "\n",
    "mdf['backward'] = mdf.apply(clicked_leaf_first, axis=1)\n",
    "pdf['first_backward'] = mdf.query('block == \"train\" and trial_index == 0').backward\n",
    "\n",
    "def n_leaf(row):\n",
    "    if not row.clicks:\n",
    "        return False\n",
    "    transfer =  EXPERIMENT in (2, 3) and row.block == \"test\"\n",
    "    leaves = transfer_leaves if transfer else small_leaves\n",
    "    return sum(click in leaves for click in row.clicks)\n",
    "\n",
    "mdf['n_leaf'] = mdf.apply(n_leaf, axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPERIMENT not in (1, 6, 7):  # run before this was a problem\n",
    "    write_tex('N-drop-previous', sum(pdf.previously_participated != \"No\"))\n",
    "    print(pdf.previously_participated.value_counts())\n",
    "    pdf = pdf.query('previously_participated == \"No\"')\n",
    "    # pdf['first_backward'] = mdf.query('trial_index == 0').backward\n",
    "    # pdf = pdf.query('not first_backward')\n",
    "    mdf = mdf.loc[pdf.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote \"9\" to \"stats/7/N-drop.tex\"\n",
      "wrote \"8.1\\%\" to \"stats/7/percent-drop.tex\"\n"
     ]
    }
   ],
   "source": [
    "n_drop = len(full_pdf) - len(pdf)\n",
    "write_tex('N-drop', f'{n_drop}')\n",
    "write_tex('percent-drop', f'{100 * n_drop / len(full_pdf):.1f}\\%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(pdf.index).to_csv(f'../data/{EXPERIMENT}/included_pids.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = Figures(path=f'figs/{EXPERIMENT}', formats=['pdf']).plot\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "blue, orange = sns.color_palette('tab10')[:2]\n",
    "gray = (0.5,)*3\n",
    "red = (1, 0.2, 0.3)\n",
    "yellow = (0.9, 0.85, 0)\n",
    "palette = {\n",
    "    'none': gray,\n",
    "    'action': blue,\n",
    "    'meta': orange,\n",
    "    'info_only': red,\n",
    "    'reward_only': yellow,\n",
    "    'both': orange,\n",
    "}\n",
    "\n",
    "palette = {\n",
    "    'none': gray,\n",
    "    'action': blue,\n",
    "    'meta': orange,\n",
    "    'info_only': red,\n",
    "    'reward_only': yellow,\n",
    "    'both': orange,\n",
    "}\n",
    "\n",
    "nice_names = {\n",
    "    'meta': 'Metacognitive',\n",
    "    'action': 'Action',\n",
    "    'none': 'None',\n",
    "    'feedback': 'Feedback',\n",
    "    'info_only': 'Information\\nOnly',\n",
    "    'reward_only': 'Delay Penalty\\nOnly',\n",
    "    'both': 'Information &\\nDelay Penalty',\n",
    "    'score': 'Average Score',\n",
    "    'backward': 'Proportion Planning Backward'\n",
    "}\n",
    "\n",
    "def reformat_labels(ax=None):\n",
    "    ax = ax or plt.gca()\n",
    "    labels = [t.get_text() for t in ax.get_xticklabels()]\n",
    "    new_labels = [nice_names.get(lab, lab) for lab in labels]\n",
    "    ax.set_xticklabels(new_labels)\n",
    "    \n",
    "def reformat_legend(ax=None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    print([nice_names.get(l, l).replace('\\n', ' ') for l in labels])\n",
    "    ax.legend(handles=handles, labels=[nice_names.get(l, l).replace('\\n', ' ') \n",
    "                                       for l in labels])\n",
    "    \n",
    "def plot_block_changes():\n",
    "    block_changes = mdf.loc[1].block.apply(Labeler()).diff().reset_index().query('block == 1').index\n",
    "    for t in block_changes:\n",
    "        plt.axvline(t-0.5, c='k', ls='--')\n",
    "\n",
    "from datetime import datetime\n",
    "# os.makedirs(f'stats/{EXPERIMENT}/', exist_ok=True)\n",
    "def result_file(name, ext='tex'):\n",
    "    file = f'stats/{EXPERIMENT}-{name}.{ext}'\n",
    "#     with open(file, 'w+') as f:\n",
    "#         timestamp = datetime.now().strftime('Created on %m/%d/%y at %H:%M:%S\\n\\n')\n",
    "#         f.write(timestamp)\n",
    "    return file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_kruskal(name):\n",
    "    out = %R kruskal.test($name ~ feedback, data=rdf)\n",
    "    out = dict(out.items())\n",
    "    df = out[\"parameter\"][0]\n",
    "    p = pval(out[\"p.value\"][0])\n",
    "    stat = out[\"statistic\"][0]\n",
    "    write_tex(f'{name}-kruskal', rf'$H = {stat:.3f}, {p}$')\n",
    "\n",
    "def cohen_d(x,y):\n",
    "    nx = len(x)\n",
    "    ny = len(y)\n",
    "    dof = nx + ny - 2\n",
    "    pooled_std =  np.sqrt(((nx-1)*np.std(x, ddof=1) ** 2 + (ny-1)*np.std(y, ddof=1) ** 2) / dof)\n",
    "    return (np.mean(x) - np.mean(y)) / pooled_std\n",
    "\n",
    "import re\n",
    "def write_independence_test(y, a, b, alternative='two.sided'):\n",
    "    # oddly, feedback == b tests a > b\n",
    "    out = %R independence_test($y ~ feedback == \"$b\",\\\n",
    "                               data=filter(rdf, feedback %in% c(\"$a\", \"$b\")),\\\n",
    "                               alternative=\"$alternative\")\n",
    "    out = str(out)\n",
    "    match = re.search('Z = (.*), p-value = (.*)', out)\n",
    "    try:\n",
    "        z, p = map(float, match.groups())\n",
    "    except:\n",
    "        print('Cannot parse independence test')\n",
    "        print(out)\n",
    "        raise Exception()\n",
    "    \n",
    "    x = rdf.set_index('feedback')[y]\n",
    "    d = cohen_d(x.loc[a], x.loc[b])\n",
    "    write_tex(f'independence-{y}-{a}-{b}', f'$d = ${d:.2f}, Z = {z:.2f}, {pval(p)}$')\n",
    "\n",
    "rdf = pdf[['test', 'feedback']].rename(columns={\n",
    "    'test': 'score'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i rdf\n",
    "library(dplyr)\n",
    "library(coin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@figure()\n",
    "def plot_test():\n",
    "    if EXPERIMENT == 6:\n",
    "        plt.figure(figsize=(12,4))\n",
    "    \n",
    "    sns.swarmplot('feedback', 'test', data=pdf, palette=palette, alpha=0.5, order=fb_order)\n",
    "    sns.pointplot('feedback', 'test', data=pdf, palette=palette, order=fb_order, \n",
    "                  scale=1, capsize=0.1, markers='o')\n",
    "    plt.xlabel('Feedback')\n",
    "    plt.ylabel(nice_names['score'])\n",
    "    test = 'Test' if EXPERIMENT == 1 else 'Transfer'\n",
    "    reformat_labels()\n",
    "#     if EXPERIMENT == 4:\n",
    "#         plt.axhline(8.879, color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_kruskal('score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPERIMENT == 6:\n",
    "    write_independence_test('score', 'both', 'none')\n",
    "    write_independence_test('score', 'info_only', 'none')\n",
    "    write_independence_test('score', 'reward_only', 'none')\n",
    "    write_independence_test('score', 'both', 'reward_only')\n",
    "    write_independence_test('score', 'both', 'info_only')\n",
    "else:\n",
    "    write_independence_test('score', 'meta', 'none')\n",
    "    if 'action' in fb_order:\n",
    "        write_independence_test('score', 'meta', 'action')\n",
    "        write_independence_test('score', 'action', 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_BOOT = 10000\n",
    "test_score = pdf.set_index('feedback').test\n",
    "\n",
    "def ci(xs):\n",
    "    return np.quantile(xs, [0.025, 0.975])\n",
    "\n",
    "def boot_means(n=N_BOOT):\n",
    "    r = {}\n",
    "    for fb in fb_order:\n",
    "        x = test_score.loc[fb]\n",
    "        means = [x.sample(frac=1, replace=True).mean() for _ in range(n)]\n",
    "        r[fb] = np.array(means)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm = boot_means()\n",
    "for fb in fb_order:\n",
    "    x = test_score.loc[fb].mean()\n",
    "    a, b = ci(bm[fb])\n",
    "    if fb == 'none':\n",
    "        tex = (rf'${x:.2f}$ points/trial (95\\% CI: [${a:.2f}$, ${b:.2f}$])')\n",
    "    else:\n",
    "        tex = (rf'${x:.2f}$ points/trial; 95\\% CI: [${a:.2f}$, ${b:.2f}$]')\n",
    "    write_tex(f'mean-{fb}', tex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_curve(var):\n",
    "    df = mdf.copy()\n",
    "    df.trial_index += 1\n",
    "    sns.lineplot('trial_index', var, hue='feedback', \n",
    "                 data=df, hue_order=fb_order, palette=palette)\n",
    "    plt.ylabel(nice_names[var])\n",
    "    plt.xlabel('Trial Number')\n",
    "    plt.gca().grid(axis='x')\n",
    "    split = mdf.query('block == \"training\"').trial_index.max()\n",
    "    plt.axvline(split+1.5, c='k', ls='--', alpha=0.3)\n",
    "    plt.xticks([1, *range(5, 31, 5)])\n",
    "    plt.xlim(df.trial_index.min()-0.5, df.trial_index.max()+0.5)\n",
    "    reformat_legend()\n",
    "    \n",
    "figure(var='backward')(learning_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(var='score')(learning_curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary in test block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_ratio(df, key):\n",
    "    name = key.replace('_', '-')\n",
    "    X = df.groupby(['feedback', key]).apply(len)\n",
    "    rate = 100 * df.groupby('feedback')[key].mean()\n",
    "\n",
    "    for c in fb_order:\n",
    "        r = rate[c]\n",
    "        write_tex(f'{name}-{c}-percent', f\"${r:.1f}$\\%\")\n",
    "\n",
    "\n",
    "report_ratio(mdf.query('block == \"test\"').copy(), 'backward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mediation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPERIMENT in (4, 6):\n",
    "    print(\"Mediation not implemented for this analysis\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = mdf.query('block == \"test\"').copy().rename(columns={'information': 'info'})\n",
    "# rdf['feedback'] = (rdf.feedback != 'none').astype(int)\n",
    "\n",
    "if EXPERIMENT == 6:\n",
    "    factors = ['info', 'reward']\n",
    "    for c in factors:\n",
    "        rdf[c] = rdf[c].astype(float)\n",
    "else:\n",
    "    factors = ['action', 'meta']\n",
    "    fb = rdf.pop('feedback')\n",
    "    for c in factors:\n",
    "        rdf[c] = (fb == c).astype(int)\n",
    "\n",
    "rdf['clicked'] = rdf.clicked.astype(int)\n",
    "rdf = rdf[[*factors, 'backward', 'clicked', 'n_clicks', 'score', 'trial_index', 'stim_i']].reset_index()\n",
    "rdf.backward.fillna(0, inplace=True)\n",
    "# rdf.trial_index = rdf.trial_index.astype(float)\n",
    "# rdf.query('action == 0', inplace=True)\n",
    "rdf = rdf.groupby('pid').mean()\n",
    "rdf.trial_index -= rdf.trial_index.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i rdf -o score\n",
    "fit = lm(score ~ backward, data=rdf)\n",
    "score = summary(fit)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i rdf -o score\n",
    "fit = lm(score ~ backward, data=rdf)\n",
    "score = summary(fit)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = dict(score.items())\n",
    "df = score['df'][1]\n",
    "est, std, t, p = score['coefficients'][1]\n",
    "write_tex(f'score-backward', f'${est:.2f}$')\n",
    "write_tex(f'score-backward-test', f'$t({df}) = {t:.2f}$, ${pval(p)}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "local({r <- getOption(\"repos\")\n",
    "       r[\"CRAN\"] <- \"https://cloud.r-project.org\" \n",
    "       options(repos=r)\n",
    "})\n",
    "# install.packages('mediation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i rdf -i EXPERIMENT -o back -o med_out\n",
    "library(mediation)\n",
    "\n",
    "if ('action' %in% colnames(rdf)) {\n",
    "    back_fit = lm(backward ~ action + meta, data=rdf)\n",
    "    score_fit = lm(score ~ backward + action + meta, data=rdf)\n",
    "# } else if (EXPERIMENT == 6) {\n",
    "#     back_fit = lm(backward ~ info + reward, data=rdf)\n",
    "#     score_fit = lm(score ~ backward + info + reward)\n",
    "} else {\n",
    "    back_fit = lm(backward ~ meta, data=rdf)\n",
    "    score_fit = lm(score ~ backward + meta, data=rdf)\n",
    "}\n",
    "med_out = mediate(back_fit, score_fit, treat=\"meta\", mediator=\"backward\")\n",
    "back = summary(back_fit)\n",
    "summary(med_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "back = dict(back.items())\n",
    "df = back['df'][1]\n",
    "for i, name in enumerate(fb_order[1:], start=1):\n",
    "    est, std, t, p = back['coefficients'][i]\n",
    "    write_tex(f'backward-lm-{name}', f'$t({df}) = {t:.3f}$, ${pval(p)}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {\n",
    "    'acme': 'd0',\n",
    "    'ade': 'z0',\n",
    "    'total': 'tau',\n",
    "    'prop': 'n0',\n",
    "}\n",
    "med = dict(med_out.items())\n",
    "\n",
    "for k, v in names.items():\n",
    "    est = med[v + ('.coef' if v == 'tau' else '')][0]\n",
    "    lo, hi = med[v+'.ci']\n",
    "    p = med[v+'.p'][0]\n",
    "    write_tex(f'mediation-{k}', f'{est:.3f}')\n",
    "    write_tex(f'mediation-{k}-ci', f'95\\% CI: [{lo:.3f}, {hi:.3f}], ${pval(p)}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Success!\")"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
